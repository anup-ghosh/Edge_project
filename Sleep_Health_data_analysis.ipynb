{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9353653,"sourceType":"datasetVersion","datasetId":5670196}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-09-14T23:17:39.328052Z","iopub.execute_input":"2024-09-14T23:17:39.328642Z","iopub.status.idle":"2024-09-14T23:17:40.890821Z","shell.execute_reply.started":"2024-09-14T23:17:39.328583Z","shell.execute_reply":"2024-09-14T23:17:40.889225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cluster Analysis, Correlation Analysis, and Predictive Modeling\n\nThis section adds advanced analysis to the health and sleep dataset, including clustering, correlation analysis, and predictive modeling.\n\n## 1. Cluster Analysis\n\n### Step 1: Data Preprocessing for Clustering\n\n# üßπ Data Preprocessing <a id='Data-Preprocessing'></a>\n\nData preprocessing is a critical step that involves cleaning, transforming, and preparing data for analysis. This section includes handling missing values, converting categorical variables to numeric, and normalizing data.","metadata":{}},{"cell_type":"code","source":"# Load the dataset\ndata_path = '/kaggle/input/health-and-sleep-statistics/Health_Sleep_Statistics.csv'\nhealth_sleep_data = pd.read_csv(data_path)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-09-14T23:17:45.375655Z","iopub.execute_input":"2024-09-14T23:17:45.376384Z","iopub.status.idle":"2024-09-14T23:17:45.40225Z","shell.execute_reply.started":"2024-09-14T23:17:45.376327Z","shell.execute_reply":"2024-09-14T23:17:45.400952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### üîÑ Converting Categorical Variables to Numerical Formats\n\nTo effectively use machine learning algorithms, we need to convert categorical variables into numerical formats. This process, known as **encoding**, transforms non-numeric data into a format that can be more easily processed by algorithms. Below is a summary of the conversions:\n\n- **Gender:** Converted to binary format:\n  - `'m'` ‚Üí `1`\n  - `'f'` ‚Üí `0`\n\n- **Physical Activity Level:** Encoded to represent different activity levels:\n  - `'low'` ‚Üí `0`\n  - `'medium'` ‚Üí `1`\n  - `'high'` ‚Üí `2`\n\n- **Dietary Habits:** Transformed to indicate diet quality:\n  - `'unhealthy'` ‚Üí `0`\n  - `'medium'` ‚Üí `1`\n  - `'healthy'` ‚Üí `2`\n\n- **Binary Variables (e.g., Sleep Disorders, Medication Usage):** Converted to numerical binary format:\n  - `'yes'` ‚Üí `1`\n  - `'no'` ‚Üí `0`\n\nThese conversions standardize the data, making it suitable for further analysis and machine learning models.\n","metadata":{}},{"cell_type":"code","source":"# Convert categorical variables to numerical representations\nhealth_sleep_data_encoded = health_sleep_data.copy()\nhealth_sleep_data_encoded['Gender'] = health_sleep_data_encoded['Gender'].map({'m': 1, 'f': 0})\nactivity_mapping = {'low': 0, 'medium': 1, 'high': 2}\nhealth_sleep_data_encoded['Physical Activity Level'] = health_sleep_data_encoded['Physical Activity Level'].map(activity_mapping)\ndiet_mapping = {'unhealthy': 0, 'medium': 1, 'healthy': 2}\nhealth_sleep_data_encoded['Dietary Habits'] = health_sleep_data_encoded['Dietary Habits'].map(diet_mapping)\nbinary_mapping = {'yes': 1, 'no': 0}\nhealth_sleep_data_encoded['Sleep Disorders'] = health_sleep_data_encoded['Sleep Disorders'].map(binary_mapping)\nhealth_sleep_data_encoded['Medication Usage'] = health_sleep_data_encoded['Medication Usage'].map(binary_mapping)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T23:17:46.032468Z","iopub.execute_input":"2024-09-14T23:17:46.033053Z","iopub.status.idle":"2024-09-14T23:17:46.050301Z","shell.execute_reply.started":"2024-09-14T23:17:46.032999Z","shell.execute_reply":"2024-09-14T23:17:46.048458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### üìè Standardizing Numerical Features for Clustering\n\nTo ensure our clustering algorithm performs optimally, we need to **standardize** the numerical features in our dataset. Standardization transforms the data to have a mean of `0` and a standard deviation of `1`, which helps in achieving uniformity and improving model performance.\n\n- **Why Standardize?** Clustering algorithms like K-Means are sensitive to the scale of data. Features with larger scales can dominate the distance calculations, skewing the results. Standardizing ensures that each feature contributes equally.\n\n- **Numerical Features Standardized:**\n  - `Age`\n  - `Sleep Quality`\n  - `Daily Steps`\n  - `Calories Burned`\n\nWe use `StandardScaler` from `scikit-learn` to apply standardization:\n\n```python\nscaler = StandardScaler()\nhealth_sleep_data_encoded[numerical_features] = scaler.fit_transform(health_sleep_data_encoded[numerical_features])\n```\n\nBy standardizing these features, we prepare our data for more effective clustering and ensure that no single feature disproportionately influences the clustering process.","metadata":{}},{"cell_type":"code","source":"# Standardize numerical features for clustering\nscaler = StandardScaler()\nnumerical_features = ['Age', 'Sleep Quality', 'Daily Steps', 'Calories Burned']\nhealth_sleep_data_encoded[numerical_features] = scaler.fit_transform(health_sleep_data_encoded[numerical_features])","metadata":{"execution":{"iopub.status.busy":"2024-09-14T23:17:49.3163Z","iopub.execute_input":"2024-09-14T23:17:49.31789Z","iopub.status.idle":"2024-09-14T23:17:49.33117Z","shell.execute_reply.started":"2024-09-14T23:17:49.317815Z","shell.execute_reply":"2024-09-14T23:17:49.329579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### üìä Determining the Optimal Number of Clusters Using the Elbow Method\n\nWhen clustering data, it's crucial to determine the right number of clusters (`K`) for optimal results. The **Elbow Method** helps us identify this number by plotting the **inertia** (sum of squared distances to the nearest cluster center) for different values of `K`.\n\n- **Inertia and the Elbow Method:**\n  - Inertia measures how internally coherent clusters are; lower values indicate tighter clusters.\n  - The \"elbow\" point in the graph shows where increasing `K` yields diminishing returns in reducing inertia. This point is considered the optimal `K`.\n\n- **Steps to Determine Optimal Clusters:**\n  1. Iterate over a range of possible cluster numbers (e.g., `1` to `10`).\n  2. For each value of `K`, apply the **K-Means** algorithm and compute inertia.\n  3. Plot the inertia values against `K` to visualize the \"elbow.\"\n\n- **Applying K-Means Clustering:**\n  - After determining the optimal number of clusters (`K = 3`), we apply K-Means clustering with this `K` value.\n  - The `n_init` parameter is explicitly set to `10` to suppress future warnings related to this parameter's default change.\n","metadata":{}},{"cell_type":"code","source":"# Determine the optimal number of clusters using the Elbow Method\ninertia = []\ncluster_range = range(1, 11)\n\n# Features to use for clustering (excluding 'User ID', 'Bedtime', and 'Wake-up Time')\nclustering_features = health_sleep_data_encoded.drop(['User ID', 'Bedtime', 'Wake-up Time'], axis=1)\n\nfor k in cluster_range:\n    # Explicitly set the `n_init` parameter to suppress the warning\n    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n    kmeans.fit(clustering_features)\n    inertia.append(kmeans.inertia_)\n\n# Plot the Elbow Method graph\nplt.figure(figsize=(10, 6))\nplt.plot(cluster_range, inertia, marker='o', linestyle='-')\nplt.title('Elbow Method for Optimal K')\nplt.xlabel('Number of Clusters (K)')\nplt.ylabel('Inertia')\nplt.xticks(cluster_range)\nplt.grid(True)\nplt.show()\n\n# Apply K-Means clustering with K = 3, with explicit `n_init` to suppress the warning\noptimal_k = 3\nkmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\nhealth_sleep_data_encoded['Cluster'] = kmeans.fit_predict(clustering_features)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T23:17:50.575759Z","iopub.execute_input":"2024-09-14T23:17:50.576314Z","iopub.status.idle":"2024-09-14T23:17:51.218607Z","shell.execute_reply.started":"2024-09-14T23:17:50.576204Z","shell.execute_reply":"2024-09-14T23:17:51.217477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### üö´ Handling Infinite Values and Visualizing Clusters\n\nWhen working with real-world data, we must address issues like infinite (`inf`) values that can arise during data processing. To ensure the data is clean and ready for clustering, we perform the following steps:\n\n1. **Convert Infinite Values to `NaN`:** Infinite values can distort analysis and model training. We convert any `inf` or `-inf` values in the dataset to `NaN` to handle them appropriately.\n\n2. Handle Missing Values (NaN): After replacing inf values, we can either fill or drop NaN values depending on the context of the analysis. Here, we choose to drop rows with NaN values to ensure data integrity.\n\n3. Apply K-Means Clustering: With a clean dataset, we apply K-Means clustering using the optimal number of clusters (K = 3). This step groups individuals based on similar patterns in selected features (e.g., Age, Sleep Quality).\n\n4. Visualize Clusters Using Pair Plot: To understand the clustering results better, we use a pair plot to visualize the distribution and relationships of selected features across the clusters. This plot provides insights into how different features contribute to the clustering.\n\nBy handling inf values, ensuring clean data, and visualizing the clustering results, we provide a comprehensive approach to understanding patterns in the health and sleep data.\n","metadata":{}},{"cell_type":"code","source":"# Ensure that any inf values in the data are converted to NaN\nhealth_sleep_data_encoded.replace([np.inf, -np.inf], np.nan, inplace=True)\n\n# Optionally, fill or drop NaN values depending on the context of your analysis\nhealth_sleep_data_encoded.dropna(inplace=True)  # Drop rows with NaN values\n\n# Apply K-Means clustering with K = 3\noptimal_k = 3\nkmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\nhealth_sleep_data_encoded['Cluster'] = kmeans.fit_predict(clustering_features)\n\n# Visualize the clusters using a pair plot for selected features\nsns.pairplot(health_sleep_data_encoded, vars=['Age', 'Sleep Quality', 'Daily Steps', 'Calories Burned'], hue='Cluster', palette='viridis', diag_kind='hist')\nplt.suptitle('Pair Plot of Clusters for Selected Features', y=1.02)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T23:17:53.090711Z","iopub.execute_input":"2024-09-14T23:17:53.092141Z","iopub.status.idle":"2024-09-14T23:18:00.713129Z","shell.execute_reply.started":"2024-09-14T23:17:53.092072Z","shell.execute_reply":"2024-09-14T23:18:00.711705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the correlation matrix for the numerical features\ncorrelation_matrix = health_sleep_data_encoded[['Age', 'Sleep Quality', 'Daily Steps', 'Calories Burned']].corr()\n\n# Plot the correlation heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\nplt.title('Correlation Heatmap of Health and Sleep Data')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T23:18:04.952894Z","iopub.execute_input":"2024-09-14T23:18:04.953429Z","iopub.status.idle":"2024-09-14T23:18:05.327507Z","shell.execute_reply.started":"2024-09-14T23:18:04.953378Z","shell.execute_reply":"2024-09-14T23:18:05.326218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert 'Bedtime' and 'Wake-up Time' to minutes since midnight for numerical processing\ndef time_to_minutes(time_str):\n    h, m = map(int, time_str.split(':'))\n    return h * 60 + m\n\n# Apply the conversion\nhealth_sleep_data_encoded['Bedtime'] = health_sleep_data_encoded['Bedtime'].apply(time_to_minutes)\nhealth_sleep_data_encoded['Wake-up Time'] = health_sleep_data_encoded['Wake-up Time'].apply(time_to_minutes)\n\n# Prepare the data for predictive modeling\n# Define target variable and features\ntarget = 'Sleep Quality'\nfeatures = health_sleep_data_encoded.drop(['Sleep Quality', 'Cluster'], axis=1)  # Exclude target and 'Cluster'\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(features, health_sleep_data_encoded[target], test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T23:18:06.294766Z","iopub.execute_input":"2024-09-14T23:18:06.295712Z","iopub.status.idle":"2024-09-14T23:18:06.310988Z","shell.execute_reply.started":"2024-09-14T23:18:06.295654Z","shell.execute_reply":"2024-09-14T23:18:06.30962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize models\nmodels = {\n    'Linear Regression': LinearRegression(),\n    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n    'XGBoost': XGBRegressor(n_estimators=100, random_state=42, objective='reg:squarederror')\n}\n\n# Train models and evaluate their performance\nmodel_performance = {}\n\nfor model_name, model in models.items():\n    model.fit(X_train, y_train)  # Train the model\n    y_pred = model.predict(X_test)  # Predict on test data\n    mse = mean_squared_error(y_test, y_pred)  # Calculate Mean Squared Error\n    r2 = r2_score(y_test, y_pred)  # Calculate R-squared value\n    model_performance[model_name] = {'MSE': mse, 'R^2': r2}\n\n# Display model performance\nmodel_performance_df = pd.DataFrame(model_performance).T\nmodel_performance_df\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T23:18:15.507138Z","iopub.execute_input":"2024-09-14T23:18:15.507594Z","iopub.status.idle":"2024-09-14T23:18:15.824725Z","shell.execute_reply.started":"2024-09-14T23:18:15.507549Z","shell.execute_reply":"2024-09-14T23:18:15.823435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}